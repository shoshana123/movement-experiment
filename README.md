# Movement-Experiment

This project was an experiment with movement, color and coding. As a former ballet dancer, I wanted to explore coding in conjunction with movement and combining these two very different fields.

This project leverages real-time human pose estimation through a machine learning model, PoseNet, from TensorFlow.js. The poses are detected in real time from the user's webcam.

Machine learning pose estimation allows for the possibility to locate key body joints and gage human pose and posture from a normal 2D image. The Google Creative Lab recently released an open source version of this model (https://medium.com/tensorflow/real-time-human-pose-estimation-in-the-browser-with-tensorflow-js-7dd0bc881cd5)

I hope you enjoy!



