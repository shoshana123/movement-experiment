# Movement Experiment

This project was an experiment with movement, color and coding. As a former ballet dancer, I wanted to explore coding in conjunction with movement and try to combine these two very different fields.

This project leverages real-time human pose estimation through a machine learning model, PoseNet, from TensorFlow.js. The poses are detected in real time from the user's webcam.

Machine learning pose estimation allows for the possibility to locate key body joints and gage human pose and posture from a normal 2D image. The Google Creative Lab recently released an open source version of this model (https://medium.com/tensorflow/real-time-human-pose-estimation-in-the-browser-with-tensorflow-js-7dd0bc881cd5)

To run this:
  1. Clone the repository to your local machine
  2. npm install </br>
    Note this version of node is 8.9.0
  3. npm run watch

I hope you enjoy!



